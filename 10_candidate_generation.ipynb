{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3612323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PATHS (edit if needed) ===\n",
    "PATH_TEST = \"test_data_question.csv\"\n",
    "PATH_P = \"P_j_given_i.csv\"\n",
    "PATH_LIFT = \"item_lift_matrix.csv\"\n",
    "PATH_JACCARD = \"item_jaccard_matrix.csv\"\n",
    "PATH_COOC = \"item_cooccurrence_counts.csv\"\n",
    "PATH_POP = \"item_stats_counts_and_freq.csv\"\n",
    "# Optional: precomputed top-10 per anchor (if you created it)\n",
    "PATH_TOP10_JSON = None  # set to None if you don't have it\n",
    "\n",
    "# === CANDIDATE GENERATION HYPERPARAMETERS ===\n",
    "TOP_N_PER_ANCHOR = 50      # how many candidates to pull per cart item (before merging)\n",
    "FALLBACK_MIN_CANDS = 30    # ensure at least this many candidates by filling with popularity\n",
    "FINAL_TOPK = 3             # we ultimately need Top-3 for submission, but we can generate more upstream\n",
    "\n",
    "# === RE-RANK (still Stage 1 aggregation) WEIGHTS for a simple score\n",
    "W_PROB = 0.60\n",
    "W_LIFT = 0.25\n",
    "W_JACC = 0.10\n",
    "W_POPU = 0.05\n",
    "\n",
    "# How to aggregate multiple anchors (items in cart) for a candidate\n",
    "AGG_PROB_METHOD = \"one_minus_prod\"  # choices: {\"sum\", \"max\", \"one_minus_prod\"}\n",
    "AGG_OTHER_METHOD = \"mean\"           # choices: {\"mean\", \"max\", \"sum\"}\n",
    "\n",
    "RANDOM_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16c27ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "def canonicalize_item(x: str) -> str:\n",
    "    \"\"\"Make item keys consistent across files.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return str(x).strip()\n",
    "\n",
    "def safe_minmax(s: pd.Series):\n",
    "    \"\"\"Min-max normalize a series; if constant, return zeros.\"\"\"\n",
    "    s = s.astype(float).fillna(0.0)\n",
    "    lo, hi = s.min(), s.max()\n",
    "    if hi - lo < 1e-12:\n",
    "        return pd.Series(np.zeros(len(s), dtype=float), index=s.index)\n",
    "    return (s - lo) / (hi - lo)\n",
    "\n",
    "def one_minus_product_of_complements(values):\n",
    "    \"\"\"Aggregate probabilities p_i -> 1 - Î (1 - p_i).\"\"\"\n",
    "    v = np.clip(np.array(values, dtype=float), 0.0, 1.0)\n",
    "    return float(1.0 - np.prod(1.0 - v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92fec1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(PATH_TEST)\n",
    "\n",
    "P = pd.read_csv(PATH_P)\n",
    "lift_df = pd.read_csv(PATH_LIFT)\n",
    "jacc_df = pd.read_csv(PATH_JACCARD)\n",
    "cooc_df = pd.read_csv(PATH_COOC)\n",
    "pop_df = pd.read_csv(PATH_POP)\n",
    "\n",
    "# Canonicalize item text-ish columns (we'll set exact column names in Step 3)\n",
    "for df in [P, lift_df, jacc_df, cooc_df, pop_df]:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col] = df[col].map(canonicalize_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1808cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== P_j_given_i.csv ====\n",
    "# Expected: one row per (anchor_item, candidate_item) with conditional probability\n",
    "COL_ANCHOR = \"anchor_item\"        # e.g., \"i\" or \"item_i\" or \"anchor\"\n",
    "COL_CAND   = \"candidate_item\"     # e.g., \"j\" or \"item_j\" or \"candidate\"\n",
    "COL_PROB   = \"P_j_given_i\"        # e.g., \"p\" or \"prob\"\n",
    "\n",
    "# If your file uses different names, uncomment and set them:\n",
    "# COL_ANCHOR = \"item_i\"\n",
    "# COL_CAND   = \"item_j\"\n",
    "# COL_PROB   = \"p_j_given_i\"\n",
    "\n",
    "# ==== item_lift_matrix.csv ====\n",
    "# Can be either long-form with (anchor, candidate, lift) or a wide square matrix.\n",
    "COL_LIFT = \"lift\"                 # if long-form. If wide, we'll melt in Step 4.\n",
    "\n",
    "# ==== item_jaccard_matrix.csv ====\n",
    "COL_JACC = \"jaccard\"              # if long-form. If wide, we'll melt in Step 4.\n",
    "\n",
    "# ==== item_cooccurrence_counts.csv ====\n",
    "COL_COOC = \"cooc_count\"           # if long-form. If wide, we'll melt in Step 4.\n",
    "\n",
    "# ==== item_stats_counts_and_freq.csv (popularity) ====\n",
    "POPULAR_COL_ITEM = \"Unnamed: 0\"    # item column in popularity table\n",
    "POPULAR_COL_FREQ = \"freq\"         # could be \"probability\" or \"relative_freq\" etc.\n",
    "\n",
    "# ==== test_data_question.csv cart columns ====\n",
    "# We'll auto-detect all columns named like \"item1\", \"item2\", ... (case-insensitive)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "136dc754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P columns: ['item', '$19.99 Crispy Feast', '10 pc Grilled Wings', '10 pc Grilled Wings Combo', '10 pc Mixed Wings', '10 pc Mixed Wings Combo', '10 pc Spicy Wings', '10 pc Spicy Wings Combo', '100 pc Family Grilled Wings', '100 pc Family Mixed Wings', '100 pc Family Spicy Wings', '100 pc Grilled Wings', '100 pc Mixed Wings', '100 pc Spicy Wings', '15 pc Crispy Strips', '15 pc Grilled Wings', '15 pc Grilled Wings Combo', '15 pc Mixed Wings', '15 pc Mixed Wings Combo', '15 pc Spicy Wings', '15 pc Spicy Wings Combo', '2 pc Crispy Strips', '20 Oz Soda', '20 pc Crispy Strips', '20 pc Grilled Wings', '20 pc Mixed Wings', '20 pc Spicy Wings', '20pc Spicy Feast Deal', '24 pc Family Grilled Wings', '24 pc Family Mixed Wings', '24 pc Family Spicy Wings', '25 pc Game Day Pack', '3 Strips Lunch', '3 pc Crispy Strips Combo', '3 pc Grilled Wings', '30 pc Crispy Strips', '30 pc Family Grilled Wings', '30 pc Family Mixed Wings', '30 pc Family Spicy Wings', '30 pc Grilled Wings', '30 pc Mixed Wings', '30 pc Spicy Wings', '32 Oz Soda', '3pc Strips Box', '4 pc Crispy Strips', '40 pc Family Grilled Wings', '40 pc Family Mixed Wings', '40 pc Family Spicy Wings', '5 pc Crispy Strips Combo', '5 pc Grilled Wings', '5 pc Spicy Wings', '50 pc Family Grilled Wings', '50 pc Family Mixed Wings', '50 pc Family Spicy Wings', '50 pc Grilled Wings', '50 pc Mixed Wings', '50 pc Spicy Wings', '6 pc Grilled Wings Combo', '6 pc Mixed Wings Combo', '6 pc Spicy Wings Combo', '6 pc Strips Meal for 2', '7 pc Crispy Strips', '75 pc Family Grilled Wings', '75 pc Family Mixed Wings', '75 pc Family Spicy Wings', '75 pc Grilled Wings', '75 pc Mixed Wings', '75 pc Spicy Wings', '8 pc Crispy Strips Combo', '8 pc Grilled Wings', '8 pc Grilled Wings Combo', '8 pc Mixed Wings Combo', '8 pc Spicy Wings Combo', '8pc Grilled Box', '8pc Wings Box', 'Add 5 Grilled Wings', 'Add 5 Spicy Wings', 'Blue Cheese Dip - Large', 'Blue Cheese Dip - Regular', 'Bottled Beverage', 'Bottled Cream Soda', 'Bottled Root Beer', 'Bottled Sparkling Water', 'Bottled Water', 'Buffalo Fries', 'Can Soda', 'Carrot Sticks', 'Celery Sticks', 'Cheese Dip - Large', 'Cheese Dip - Medium', 'Cheese Dip - Regular', 'Cheese Fries - Large', 'Cheese Fries - Regular', 'Chicken Sub', 'Chicken Sub Combo', 'Dipping Sauce', 'Domestic Draft Lager', 'Domestic Lager', 'Domestic Lager Special', 'Drink Upgrade', 'Extra Sauce', 'Flavor Platter', 'Flavor Platter Grilled', 'Fried Corn - Large', 'Fried Corn - Regular', 'Grilled Lunch Combo', 'Honey Mustard Dip - Large', 'Honey Mustard Dip - Regular', 'Hot Honey Strips 3pc', 'Large Buffalo Fries', 'Large Carrot Sticks', 'Large Celery Sticks', 'Large Fruit Punch', 'Large Lemonade', 'Large Veggie Sticks', 'Large Veggie Sticks Spicy', 'Legendary Feast Bundle', 'Premium Lager', 'Ranch Dip - Large', 'Ranch Dip - Regular', 'Regular Buffalo Fries', 'Seasoning Pack', 'Sports Drink', 'Sub Box', 'Triple Chocolate Cake', 'Triple Feast Deal', 'Veggie Sticks', 'Veggie Sticks Spicy', 'Voodoo Fries - Large', 'Voodoo Fries - Regular', 'Wings Lunch Combo']\n",
      "lift columns: ['Unnamed: 0', '$19.99 Crispy Feast', '10 pc Grilled Wings', '10 pc Grilled Wings Combo', '10 pc Mixed Wings', '10 pc Mixed Wings Combo', '10 pc Spicy Wings', '10 pc Spicy Wings Combo', '100 pc Family Grilled Wings', '100 pc Family Mixed Wings', '100 pc Family Spicy Wings', '100 pc Grilled Wings', '100 pc Mixed Wings', '100 pc Spicy Wings', '15 pc Crispy Strips', '15 pc Grilled Wings', '15 pc Grilled Wings Combo', '15 pc Mixed Wings', '15 pc Mixed Wings Combo', '15 pc Spicy Wings', '15 pc Spicy Wings Combo', '2 pc Crispy Strips', '20 Oz Soda', '20 pc Crispy Strips', '20 pc Grilled Wings', '20 pc Mixed Wings', '20 pc Spicy Wings', '20pc Spicy Feast Deal', '24 pc Family Grilled Wings', '24 pc Family Mixed Wings', '24 pc Family Spicy Wings', '25 pc Game Day Pack', '3 Strips Lunch', '3 pc Crispy Strips Combo', '3 pc Grilled Wings', '30 pc Crispy Strips', '30 pc Family Grilled Wings', '30 pc Family Mixed Wings', '30 pc Family Spicy Wings', '30 pc Grilled Wings', '30 pc Mixed Wings', '30 pc Spicy Wings', '32 Oz Soda', '3pc Strips Box', '4 pc Crispy Strips', '40 pc Family Grilled Wings', '40 pc Family Mixed Wings', '40 pc Family Spicy Wings', '5 pc Crispy Strips Combo', '5 pc Grilled Wings', '5 pc Spicy Wings', '50 pc Family Grilled Wings', '50 pc Family Mixed Wings', '50 pc Family Spicy Wings', '50 pc Grilled Wings', '50 pc Mixed Wings', '50 pc Spicy Wings', '6 pc Grilled Wings Combo', '6 pc Mixed Wings Combo', '6 pc Spicy Wings Combo', '6 pc Strips Meal for 2', '7 pc Crispy Strips', '75 pc Family Grilled Wings', '75 pc Family Mixed Wings', '75 pc Family Spicy Wings', '75 pc Grilled Wings', '75 pc Mixed Wings', '75 pc Spicy Wings', '8 pc Crispy Strips Combo', '8 pc Grilled Wings', '8 pc Grilled Wings Combo', '8 pc Mixed Wings Combo', '8 pc Spicy Wings Combo', '8pc Grilled Box', '8pc Wings Box', 'Add 5 Grilled Wings', 'Add 5 Spicy Wings', 'Blue Cheese Dip - Large', 'Blue Cheese Dip - Regular', 'Bottled Beverage', 'Bottled Cream Soda', 'Bottled Root Beer', 'Bottled Sparkling Water', 'Bottled Water', 'Buffalo Fries', 'Can Soda', 'Carrot Sticks', 'Celery Sticks', 'Cheese Dip - Large', 'Cheese Dip - Medium', 'Cheese Dip - Regular', 'Cheese Fries - Large', 'Cheese Fries - Regular', 'Chicken Sub', 'Chicken Sub Combo', 'Dipping Sauce', 'Domestic Draft Lager', 'Domestic Lager', 'Domestic Lager Special', 'Drink Upgrade', 'Extra Sauce', 'Flavor Platter', 'Flavor Platter Grilled', 'Fried Corn - Large', 'Fried Corn - Regular', 'Grilled Lunch Combo', 'Honey Mustard Dip - Large', 'Honey Mustard Dip - Regular', 'Hot Honey Strips 3pc', 'Large Buffalo Fries', 'Large Carrot Sticks', 'Large Celery Sticks', 'Large Fruit Punch', 'Large Lemonade', 'Large Veggie Sticks', 'Large Veggie Sticks Spicy', 'Legendary Feast Bundle', 'Premium Lager', 'Ranch Dip - Large', 'Ranch Dip - Regular', 'Regular Buffalo Fries', 'Seasoning Pack', 'Sports Drink', 'Sub Box', 'Triple Chocolate Cake', 'Triple Feast Deal', 'Veggie Sticks', 'Veggie Sticks Spicy', 'Voodoo Fries - Large', 'Voodoo Fries - Regular', 'Wings Lunch Combo']\n",
      "jacc columns: ['item', '$19.99 Crispy Feast', '10 pc Grilled Wings', '10 pc Grilled Wings Combo', '10 pc Mixed Wings', '10 pc Mixed Wings Combo', '10 pc Spicy Wings', '10 pc Spicy Wings Combo', '100 pc Family Grilled Wings', '100 pc Family Mixed Wings', '100 pc Family Spicy Wings', '100 pc Grilled Wings', '100 pc Mixed Wings', '100 pc Spicy Wings', '15 pc Crispy Strips', '15 pc Grilled Wings', '15 pc Grilled Wings Combo', '15 pc Mixed Wings', '15 pc Mixed Wings Combo', '15 pc Spicy Wings', '15 pc Spicy Wings Combo', '2 pc Crispy Strips', '20 Oz Soda', '20 pc Crispy Strips', '20 pc Grilled Wings', '20 pc Mixed Wings', '20 pc Spicy Wings', '20pc Spicy Feast Deal', '24 pc Family Grilled Wings', '24 pc Family Mixed Wings', '24 pc Family Spicy Wings', '25 pc Game Day Pack', '3 Strips Lunch', '3 pc Crispy Strips Combo', '3 pc Grilled Wings', '30 pc Crispy Strips', '30 pc Family Grilled Wings', '30 pc Family Mixed Wings', '30 pc Family Spicy Wings', '30 pc Grilled Wings', '30 pc Mixed Wings', '30 pc Spicy Wings', '32 Oz Soda', '3pc Strips Box', '4 pc Crispy Strips', '40 pc Family Grilled Wings', '40 pc Family Mixed Wings', '40 pc Family Spicy Wings', '5 pc Crispy Strips Combo', '5 pc Grilled Wings', '5 pc Spicy Wings', '50 pc Family Grilled Wings', '50 pc Family Mixed Wings', '50 pc Family Spicy Wings', '50 pc Grilled Wings', '50 pc Mixed Wings', '50 pc Spicy Wings', '6 pc Grilled Wings Combo', '6 pc Mixed Wings Combo', '6 pc Spicy Wings Combo', '6 pc Strips Meal for 2', '7 pc Crispy Strips', '75 pc Family Grilled Wings', '75 pc Family Mixed Wings', '75 pc Family Spicy Wings', '75 pc Grilled Wings', '75 pc Mixed Wings', '75 pc Spicy Wings', '8 pc Crispy Strips Combo', '8 pc Grilled Wings', '8 pc Grilled Wings Combo', '8 pc Mixed Wings Combo', '8 pc Spicy Wings Combo', '8pc Grilled Box', '8pc Wings Box', 'Add 5 Grilled Wings', 'Add 5 Spicy Wings', 'Blue Cheese Dip - Large', 'Blue Cheese Dip - Regular', 'Bottled Beverage', 'Bottled Cream Soda', 'Bottled Root Beer', 'Bottled Sparkling Water', 'Bottled Water', 'Buffalo Fries', 'Can Soda', 'Carrot Sticks', 'Celery Sticks', 'Cheese Dip - Large', 'Cheese Dip - Medium', 'Cheese Dip - Regular', 'Cheese Fries - Large', 'Cheese Fries - Regular', 'Chicken Sub', 'Chicken Sub Combo', 'Dipping Sauce', 'Domestic Draft Lager', 'Domestic Lager', 'Domestic Lager Special', 'Drink Upgrade', 'Extra Sauce', 'Flavor Platter', 'Flavor Platter Grilled', 'Fried Corn - Large', 'Fried Corn - Regular', 'Grilled Lunch Combo', 'Honey Mustard Dip - Large', 'Honey Mustard Dip - Regular', 'Hot Honey Strips 3pc', 'Large Buffalo Fries', 'Large Carrot Sticks', 'Large Celery Sticks', 'Large Fruit Punch', 'Large Lemonade', 'Large Veggie Sticks', 'Large Veggie Sticks Spicy', 'Legendary Feast Bundle', 'Premium Lager', 'Ranch Dip - Large', 'Ranch Dip - Regular', 'Regular Buffalo Fries', 'Seasoning Pack', 'Sports Drink', 'Sub Box', 'Triple Chocolate Cake', 'Triple Feast Deal', 'Veggie Sticks', 'Veggie Sticks Spicy', 'Voodoo Fries - Large', 'Voodoo Fries - Regular', 'Wings Lunch Combo']\n",
      "cooc columns: ['item', '$19.99 Crispy Feast', '10 pc Grilled Wings', '10 pc Grilled Wings Combo', '10 pc Mixed Wings', '10 pc Mixed Wings Combo', '10 pc Spicy Wings', '10 pc Spicy Wings Combo', '100 pc Family Grilled Wings', '100 pc Family Mixed Wings', '100 pc Family Spicy Wings', '100 pc Grilled Wings', '100 pc Mixed Wings', '100 pc Spicy Wings', '15 pc Crispy Strips', '15 pc Grilled Wings', '15 pc Grilled Wings Combo', '15 pc Mixed Wings', '15 pc Mixed Wings Combo', '15 pc Spicy Wings', '15 pc Spicy Wings Combo', '2 pc Crispy Strips', '20 Oz Soda', '20 pc Crispy Strips', '20 pc Grilled Wings', '20 pc Mixed Wings', '20 pc Spicy Wings', '20pc Spicy Feast Deal', '24 pc Family Grilled Wings', '24 pc Family Mixed Wings', '24 pc Family Spicy Wings', '25 pc Game Day Pack', '3 Strips Lunch', '3 pc Crispy Strips Combo', '3 pc Grilled Wings', '30 pc Crispy Strips', '30 pc Family Grilled Wings', '30 pc Family Mixed Wings', '30 pc Family Spicy Wings', '30 pc Grilled Wings', '30 pc Mixed Wings', '30 pc Spicy Wings', '32 Oz Soda', '3pc Strips Box', '4 pc Crispy Strips', '40 pc Family Grilled Wings', '40 pc Family Mixed Wings', '40 pc Family Spicy Wings', '5 pc Crispy Strips Combo', '5 pc Grilled Wings', '5 pc Spicy Wings', '50 pc Family Grilled Wings', '50 pc Family Mixed Wings', '50 pc Family Spicy Wings', '50 pc Grilled Wings', '50 pc Mixed Wings', '50 pc Spicy Wings', '6 pc Grilled Wings Combo', '6 pc Mixed Wings Combo', '6 pc Spicy Wings Combo', '6 pc Strips Meal for 2', '7 pc Crispy Strips', '75 pc Family Grilled Wings', '75 pc Family Mixed Wings', '75 pc Family Spicy Wings', '75 pc Grilled Wings', '75 pc Mixed Wings', '75 pc Spicy Wings', '8 pc Crispy Strips Combo', '8 pc Grilled Wings', '8 pc Grilled Wings Combo', '8 pc Mixed Wings Combo', '8 pc Spicy Wings Combo', '8pc Grilled Box', '8pc Wings Box', 'Add 5 Grilled Wings', 'Add 5 Spicy Wings', 'Blue Cheese Dip - Large', 'Blue Cheese Dip - Regular', 'Bottled Beverage', 'Bottled Cream Soda', 'Bottled Root Beer', 'Bottled Sparkling Water', 'Bottled Water', 'Buffalo Fries', 'Can Soda', 'Carrot Sticks', 'Celery Sticks', 'Cheese Dip - Large', 'Cheese Dip - Medium', 'Cheese Dip - Regular', 'Cheese Fries - Large', 'Cheese Fries - Regular', 'Chicken Sub', 'Chicken Sub Combo', 'Dipping Sauce', 'Domestic Draft Lager', 'Domestic Lager', 'Domestic Lager Special', 'Drink Upgrade', 'Extra Sauce', 'Flavor Platter', 'Flavor Platter Grilled', 'Fried Corn - Large', 'Fried Corn - Regular', 'Grilled Lunch Combo', 'Honey Mustard Dip - Large', 'Honey Mustard Dip - Regular', 'Hot Honey Strips 3pc', 'Large Buffalo Fries', 'Large Carrot Sticks', 'Large Celery Sticks', 'Large Fruit Punch', 'Large Lemonade', 'Large Veggie Sticks', 'Large Veggie Sticks Spicy', 'Legendary Feast Bundle', 'Premium Lager', 'Ranch Dip - Large', 'Ranch Dip - Regular', 'Regular Buffalo Fries', 'Seasoning Pack', 'Sports Drink', 'Sub Box', 'Triple Chocolate Cake', 'Triple Feast Deal', 'Veggie Sticks', 'Veggie Sticks Spicy', 'Voodoo Fries - Large', 'Voodoo Fries - Regular', 'Wings Lunch Combo']\n",
      "pop columns: ['Unnamed: 0', 'count', 'freq']\n",
      "test columns: ['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_ID', 'ORDER_CHANNEL_NAME', 'ORDER_SUBCHANNEL_NAME', 'ORDER_OCCASION_NAME', 'CUSTOMER_TYPE', 'item1', 'item2', 'item3']\n"
     ]
    }
   ],
   "source": [
    "print(\"P columns:\", P.columns.tolist())\n",
    "print(\"lift columns:\", lift_df.columns.tolist())\n",
    "print(\"jacc columns:\", jacc_df.columns.tolist())\n",
    "print(\"cooc columns:\", cooc_df.columns.tolist())\n",
    "print(\"pop columns:\", pop_df.columns.tolist())\n",
    "print(\"test columns:\", test_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "362aee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_long_pairs(df, value_col, item_id_col=None):\n",
    "    \"\"\"\n",
    "    Convert a square matrix to long-form (anchor, candidate, value_col).\n",
    "    If already long (contains both anchor & candidate), return as-is.\n",
    "    - item_id_col: if the first column holds the row item names.\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    # Heuristic: already long if it has at least two string/object columns\n",
    "    str_cols = [c for c in cols if df[c].dtype == \"object\"]\n",
    "    if len(str_cols) >= 2 and value_col in cols:\n",
    "        # Looks long already\n",
    "        return df.rename(columns={str_cols[0]: COL_ANCHOR, str_cols[1]: COL_CAND})\n",
    "    # Otherwise, assume wide matrix with row index or first col as item id\n",
    "    if item_id_col is None:\n",
    "        item_id_col = cols[0]\n",
    "    wide = df.copy()\n",
    "    wide[item_id_col] = wide[item_id_col].map(canonicalize_item)\n",
    "    long_df = wide.melt(id_vars=[item_id_col], var_name=COL_CAND, value_name=value_col)\n",
    "    long_df.rename(columns={item_id_col: COL_ANCHOR}, inplace=True)\n",
    "    long_df[COL_CAND] = long_df[COL_CAND].map(canonicalize_item)\n",
    "    return long_df\n",
    "\n",
    "# Convert to long if needed\n",
    "lift_pairs  = to_long_pairs(lift_df,  COL_LIFT)\n",
    "jacc_pairs  = to_long_pairs(jacc_df,  COL_JACC)\n",
    "cooc_pairs  = to_long_pairs(cooc_df,  COL_COOC)\n",
    "\n",
    "# Standardize key columns text\n",
    "for df in [P, lift_pairs, jacc_pairs, cooc_pairs]:\n",
    "    for c in [COL_ANCHOR, COL_CAND]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].map(canonicalize_item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b1fc08d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert P from wide to long form\n",
    "P_long = P.melt(id_vars=['item'],  # <-- replace 'item' with whatever the first column name is in P_j_given_i.csv\n",
    "                var_name=COL_CAND,\n",
    "                value_name=COL_PROB)\n",
    "P_long.rename(columns={'item': COL_ANCHOR}, inplace=True)\n",
    "\n",
    "# Canonicalize names\n",
    "P_long[COL_ANCHOR] = P_long[COL_ANCHOR].map(canonicalize_item)\n",
    "P_long[COL_CAND]   = P_long[COL_CAND].map(canonicalize_item)\n",
    "\n",
    "# Overwrite P\n",
    "P = P_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3dcbd267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure P has the expected columns\n",
    "assert {COL_ANCHOR, COL_CAND, COL_PROB}.issubset(P.columns), \"Fix column mappings in Step 3.\"\n",
    "\n",
    "# Sort P by prob desc for each anchor and keep TOP_N_PER_ANCHOR rows per anchor\n",
    "P_sorted = P.sort_values([COL_ANCHOR, COL_PROB], ascending=[True, False]).copy()\n",
    "P_topN = P_sorted.groupby(COL_ANCHOR, as_index=False).head(TOP_N_PER_ANCHOR)\n",
    "\n",
    "# Optional: load precomputed top-k by anchor\n",
    "topk_dict = {}\n",
    "if PATH_TOP10_JSON and len(PATH_TOP10_JSON) > 0:\n",
    "    try:\n",
    "        with open(PATH_TOP10_JSON, \"r\") as f:\n",
    "            topk_dict = json.load(f)\n",
    "        # canonicalize keys\n",
    "        topk_dict = {canonicalize_item(k): [canonicalize_item(x) for x in v] for k, v in topk_dict.items()}\n",
    "    except Exception as e:\n",
    "        print(\"Skipping JSON top-k; reason:\", e)\n",
    "\n",
    "# Build dict: anchor -> DataFrame of candidates from P_topN\n",
    "P_by_anchor = {a: g[[COL_CAND, COL_PROB]].reset_index(drop=True)\n",
    "               for a, g in P_topN.groupby(COL_ANCHOR)}\n",
    "\n",
    "# Fast join frames on (anchor, candidate)\n",
    "# Merge lift/jacc/cooc so we can bring these signals in later\n",
    "lift_pairs = lift_pairs[[COL_ANCHOR, COL_CAND, COL_LIFT]].dropna()\n",
    "jacc_pairs = jacc_pairs[[COL_ANCHOR, COL_CAND, COL_JACC]].dropna()\n",
    "cooc_pairs = cooc_pairs[[COL_ANCHOR, COL_CAND, COL_COOC]].dropna()\n",
    "\n",
    "# Global popularity table\n",
    "pop_df = pop_df[[POPULAR_COL_ITEM, POPULAR_COL_FREQ]].dropna()\n",
    "pop_df[POPULAR_COL_ITEM] = pop_df[POPULAR_COL_ITEM].map(canonicalize_item)\n",
    "pop_df = pop_df.sort_values(POPULAR_COL_FREQ, ascending=False).reset_index(drop=True)\n",
    "\n",
    "POPULAR_ITEMS = pop_df[POPULAR_COL_ITEM].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "056debd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-detect item columns in test\n",
    "item_cols = [c for c in test_df.columns if c.lower().startswith(\"item\")]\n",
    "item_cols = sorted(item_cols, key=lambda x: int(''.join([ch for ch in x if ch.isdigit()]) or 0))  # item1, item2, ...\n",
    "\n",
    "def extract_cart_items(row):\n",
    "    items = []\n",
    "    for c in item_cols:\n",
    "        val = row.get(c, np.nan)\n",
    "        if pd.notna(val) and str(val).strip():\n",
    "            items.append(canonicalize_item(val))\n",
    "    return [it for it in items if it]  # non-empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e51e4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates_for_cart(cart_items):\n",
    "    # 1) Collect per-anchor candidates\n",
    "    per_anchor_frames = []\n",
    "    for anchor in cart_items:\n",
    "        # Prefer JSON top-k if available\n",
    "        if topk_dict and anchor in topk_dict:\n",
    "            cand_list = topk_dict[anchor]\n",
    "            df = pd.DataFrame({COL_CAND: cand_list})\n",
    "            # bring probability if available\n",
    "            df = df.merge(P[[COL_ANCHOR, COL_CAND, COL_PROB]][P[COL_ANCHOR]==anchor],\n",
    "                          on=COL_CAND, how=\"left\")\n",
    "            df[COL_PROB] = df[COL_PROB].fillna(0.0)\n",
    "        else:\n",
    "            # Use P_by_anchor fallback\n",
    "            df = P_by_anchor.get(anchor, pd.DataFrame(columns=[COL_CAND, COL_PROB])).copy()\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # Attach other signals for this (anchor, candidate) pair\n",
    "        df[COL_ANCHOR] = anchor\n",
    "        df = df.merge(lift_pairs, on=[COL_ANCHOR, COL_CAND], how=\"left\")\n",
    "        df = df.merge(jacc_pairs, on=[COL_ANCHOR, COL_CAND], how=\"left\")\n",
    "        df = df.merge(cooc_pairs, on=[COL_ANCHOR, COL_CAND], how=\"left\")\n",
    "        per_anchor_frames.append(df)\n",
    "\n",
    "    if not per_anchor_frames:\n",
    "        # No anchor had candidates â return popularity (excluding cart items)\n",
    "        fallback = pop_df[~pop_df[POPULAR_COL_ITEM].isin(cart_items)].copy()\n",
    "        fallback = fallback.rename(columns={POPULAR_COL_ITEM: COL_CAND,\n",
    "                                            POPULAR_COL_FREQ: \"popularity\"})\n",
    "        fallback[\"final_score\"] = fallback[\"popularity\"].rank(pct=True, ascending=False)\n",
    "        return fallback[[COL_CAND, \"final_score\"]].head(FALLBACK_MIN_CANDS)\n",
    "\n",
    "    # 2) Combine all anchorsâ candidates\n",
    "    cand_pairs = pd.concat(per_anchor_frames, ignore_index=True)\n",
    "\n",
    "    # Remove items already in cart\n",
    "    cand_pairs = cand_pairs[~cand_pairs[COL_CAND].isin(cart_items)].copy()\n",
    "\n",
    "    # 3) Aggregate across anchors for each candidate\n",
    "    #    - prob aggregation: sum / max / 1 - Î (1 - p)\n",
    "    #    - other signals: mean / max / sum\n",
    "    agg_funcs = {\n",
    "        COL_PROB: (lambda s: {\n",
    "            \"sum\": s.sum(),\n",
    "            \"max\": s.max(),\n",
    "            \"one_minus_prod\": one_minus_product_of_complements(s)\n",
    "        }[AGG_PROB_METHOD]),\n",
    "        COL_LIFT: (lambda s: {\n",
    "            \"mean\": s.mean(skipna=True),\n",
    "            \"max\": s.max(skipna=True),\n",
    "            \"sum\": s.sum(skipna=True)\n",
    "        }[AGG_OTHER_METHOD]),\n",
    "        COL_JACC: (lambda s: {\n",
    "            \"mean\": s.mean(skipna=True),\n",
    "            \"max\": s.max(skipna=True),\n",
    "            \"sum\": s.sum(skipna=True)\n",
    "        }[AGG_OTHER_METHOD]),\n",
    "        COL_COOC: (lambda s: {\n",
    "            \"mean\": s.mean(skipna=True),\n",
    "            \"max\": s.max(skipna=True),\n",
    "            \"sum\": s.sum(skipna=True)\n",
    "        }[AGG_OTHER_METHOD]),\n",
    "    }\n",
    "\n",
    "    grouped = cand_pairs.groupby(COL_CAND).agg({\n",
    "        COL_PROB: agg_funcs[COL_PROB],\n",
    "        COL_LIFT: agg_funcs[COL_LIFT] if COL_LIFT in cand_pairs.columns else \"mean\",\n",
    "        COL_JACC: agg_funcs[COL_JACC] if COL_JACC in cand_pairs.columns else \"mean\",\n",
    "        COL_COOC: agg_funcs[COL_COOC] if COL_COOC in cand_pairs.columns else \"sum\",\n",
    "    }).reset_index()\n",
    "\n",
    "    # 4) Attach popularity (global) for tie-breaking\n",
    "    grouped = grouped.merge(pop_df.rename(columns={POPULAR_COL_ITEM: COL_CAND,\n",
    "                                                   POPULAR_COL_FREQ: \"popularity\"}),\n",
    "                            on=COL_CAND, how=\"left\")\n",
    "\n",
    "    # 5) Normalize each signal and combine with weights\n",
    "    for col in [COL_PROB, COL_LIFT, COL_JACC, \"popularity\"]:\n",
    "        if col not in grouped.columns:\n",
    "            grouped[col] = 0.0\n",
    "        grouped[f\"{col}_norm\"] = safe_minmax(grouped[col])\n",
    "\n",
    "    grouped[\"final_score\"] = (\n",
    "        W_PROB * grouped[f\"{COL_PROB}_norm\"] +\n",
    "        W_LIFT * grouped[f\"{COL_LIFT}_norm\"] +\n",
    "        W_JACC * grouped[f\"{COL_JACC}_norm\"] +\n",
    "        W_POPU * grouped[\"popularity_norm\"]\n",
    "    )\n",
    "\n",
    "    # 6) Popularity fallback to guarantee coverage\n",
    "    need = max(0, FALLBACK_MIN_CANDS - len(grouped))\n",
    "    if need > 0:\n",
    "        fallback = pop_df[~pop_df[POPULAR_COL_ITEM].isin(set(grouped[COL_CAND]).union(cart_items))] \\\n",
    "                    .head(need).copy()\n",
    "        fallback = fallback.rename(columns={POPULAR_COL_ITEM: COL_CAND})\n",
    "        fallback[\"final_score\"] = 0.0  # will sink below existing candidates\n",
    "        grouped = pd.concat([grouped[[COL_CAND, \"final_score\"]], fallback[[COL_CAND, \"final_score\"]]],\n",
    "                            ignore_index=True)\n",
    "\n",
    "    # 7) Return sorted candidate list\n",
    "    grouped = grouped.sort_values(\"final_score\", ascending=False).reset_index(drop=True)\n",
    "    return grouped[[COL_CAND, \"final_score\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "119d6652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cart items: ['Chicken Sub Combo', '6 pc Grilled Wings Combo', 'Ranch Dip - Regular']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>candidate_item</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10 pc Grilled Wings Combo</td>\n",
       "      <td>0.791638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8 pc Grilled Wings Combo</td>\n",
       "      <td>0.711733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 pc Crispy Strips</td>\n",
       "      <td>0.669020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Regular Buffalo Fries</td>\n",
       "      <td>0.566795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10 pc Grilled Wings</td>\n",
       "      <td>0.554154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6 pc Spicy Wings Combo</td>\n",
       "      <td>0.523215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10 pc Spicy Wings</td>\n",
       "      <td>0.484875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fried Corn - Regular</td>\n",
       "      <td>0.434329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20pc Spicy Feast Deal</td>\n",
       "      <td>0.426439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chicken Sub</td>\n",
       "      <td>0.411842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              candidate_item  final_score\n",
       "0  10 pc Grilled Wings Combo     0.791638\n",
       "1   8 pc Grilled Wings Combo     0.711733\n",
       "2         2 pc Crispy Strips     0.669020\n",
       "3      Regular Buffalo Fries     0.566795\n",
       "4        10 pc Grilled Wings     0.554154\n",
       "5     6 pc Spicy Wings Combo     0.523215\n",
       "6          10 pc Spicy Wings     0.484875\n",
       "7       Fried Corn - Regular     0.434329\n",
       "8      20pc Spicy Feast Deal     0.426439\n",
       "9                Chicken Sub     0.411842"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick a random row from test and get its cart items\n",
    "row = test_df.sample(1, random_state=RANDOM_SEED).iloc[0]\n",
    "cart_items = extract_cart_items(row)\n",
    "print(\"Cart items:\", cart_items)\n",
    "\n",
    "cand_df = get_candidates_for_cart(cart_items)\n",
    "cand_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e3834df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_bucket(name: str) -> str:\n",
    "    n = name.lower()\n",
    "    if \"fries\" in n: return \"fries\"\n",
    "    if \"combo\" in n: return \"combo\"\n",
    "    if \"dip\" in n: return \"dip\"\n",
    "    if \"corn\" in n: return \"sides\"\n",
    "    if any(w in n for w in [\"cake\",\"brownie\",\"cookie\"]): return \"dessert\"\n",
    "    if \"drink\" in n or \"soda\" in n: return \"drink\"\n",
    "    if \"wings\" in n and \"spicy\" in n: return \"wings_spicy\"\n",
    "    if \"wings\" in n and \"grilled\" in n: return \"wings_grilled\"\n",
    "    if \"wings\" in n: return \"wings\"\n",
    "    if \"strips\" in n: return \"strips\"\n",
    "    return \"other\"\n",
    "\n",
    "def pick_diverse_topk(ranked_df, k=3):\n",
    "    seen = set()\n",
    "    chosen = []\n",
    "    for _, r in ranked_df.iterrows():\n",
    "        b = item_bucket(r['candidate_item'])\n",
    "        if b in seen: \n",
    "            continue\n",
    "        chosen.append(r['candidate_item'])\n",
    "        seen.add(b)\n",
    "        if len(chosen) == k:\n",
    "            break\n",
    "    # backfill if we didnât hit k\n",
    "    if len(chosen) < k:\n",
    "        for _, r in ranked_df.iterrows():\n",
    "            if r['candidate_item'] not in chosen:\n",
    "                chosen.append(r['candidate_item'])\n",
    "                if len(chosen) == k: break\n",
    "    return chosen[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e45fcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: stage1_candidate_recommendations_top{FINAL_TOPK}.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORDER_ID</th>\n",
       "      <th>RECOMMENDATION_1</th>\n",
       "      <th>RECOMMENDATION_2</th>\n",
       "      <th>RECOMMENDATION_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9351345556</td>\n",
       "      <td>10 pc Grilled Wings Combo</td>\n",
       "      <td>2 pc Crispy Strips</td>\n",
       "      <td>Regular Buffalo Fries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3595377080</td>\n",
       "      <td>Ranch Dip - Regular</td>\n",
       "      <td>10 pc Grilled Wings</td>\n",
       "      <td>2 pc Crispy Strips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4071757785</td>\n",
       "      <td>Regular Buffalo Fries</td>\n",
       "      <td>10 pc Grilled Wings</td>\n",
       "      <td>Ranch Dip - Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3931766769</td>\n",
       "      <td>Ranch Dip - Regular</td>\n",
       "      <td>Regular Buffalo Fries</td>\n",
       "      <td>Ranch Dip - Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3739700809</td>\n",
       "      <td>Ranch Dip - Regular</td>\n",
       "      <td>Large Buffalo Fries</td>\n",
       "      <td>10 pc Spicy Wings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ORDER_ID           RECOMMENDATION_1       RECOMMENDATION_2  \\\n",
       "0  9351345556  10 pc Grilled Wings Combo     2 pc Crispy Strips   \n",
       "1  3595377080        Ranch Dip - Regular    10 pc Grilled Wings   \n",
       "2  4071757785      Regular Buffalo Fries    10 pc Grilled Wings   \n",
       "3  3931766769        Ranch Dip - Regular  Regular Buffalo Fries   \n",
       "4  3739700809        Ranch Dip - Regular    Large Buffalo Fries   \n",
       "\n",
       "        RECOMMENDATION_3  \n",
       "0  Regular Buffalo Fries  \n",
       "1     2 pc Crispy Strips  \n",
       "2      Ranch Dip - Large  \n",
       "3      Ranch Dip - Large  \n",
       "4      10 pc Spicy Wings  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend_topk_for_row(row, k=3):\n",
    "    cart_items = extract_cart_items(row)\n",
    "    cands = get_candidates_for_cart(cart_items)\n",
    "    topk = pick_diverse_topk(cands, k=k)\n",
    "    while len(topk) < k: topk.append(\"\")\n",
    "    return pd.Series({f\"RECOMMENDATION_{i+1}\": topk[i] for i in range(k)})\n",
    "\n",
    "reco_cols = [f\"RECOMMENDATION_{i+1}\" for i in range(FINAL_TOPK)]\n",
    "reco_df = test_df.copy()\n",
    "reco_df[reco_cols] = test_df.apply(lambda r: recommend_topk_for_row(r, k=FINAL_TOPK), axis=1)\n",
    "\n",
    "# Save an output (intermediate) file; you'll paste these cols into the official template if needed\n",
    "OUT_PATH = \"stage1_candidate_recommendations_top3_v2.csv\"\n",
    "reco_df[[\"ORDER_ID\"] + reco_cols].to_csv(OUT_PATH, index=False)\n",
    "print(f\"Saved: {OUT_PATH}\")\n",
    "reco_df.head(5)[[\"ORDER_ID\"] + reco_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581b77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
