{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5317ed82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bae700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 0) File paths (edit if needed)\n",
    "# ---------------------------\n",
    "orders_fp = \"order_data_cleaned_and_encoded.csv\"    # your cleaned orders\n",
    "cust_fp   = \"customer_data_cleaned_and_encoded.csv\"             # your encoded customers (registered/guest/special_membership)\n",
    "store_fp  = \"store_data_cleaned_and_encoded.csv\"                # your encoded stores (store_number + city dummies + STATE + flags)\n",
    "out_fp    = \"master_orders_customers_stores.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf24b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 1) Read files and normalize key dtypes\n",
    "# ---------------------------\n",
    "orders = pd.read_csv(orders_fp, dtype=str)   # read everything as str to avoid join-dtype problems\n",
    "cust   = pd.read_csv(cust_fp, dtype=str)\n",
    "store  = pd.read_csv(store_fp, dtype=str)\n",
    "\n",
    "# If some numeric columns are needed later, you'll cast them back.\n",
    "# Ensure keys exist\n",
    "assert 'CUSTOMER_ID' in orders.columns, \"orders missing CUSTOMER_ID\"\n",
    "assert 'STORE_NUMBER' in orders.columns, \"orders missing STORE_NUMBER\"\n",
    "assert 'CUSTOMER_ID' in cust.columns,   \"customer file missing CUSTOMER_ID\"\n",
    "assert 'STORE_NUMBER' in store.columns,  \"store file missing STORE_NUMBER\"\n",
    "\n",
    "# Keep a copy of the original row count for verification\n",
    "n_orders = len(orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb051275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 2) Prepare customer frame: drop any original CUSTOMER_TYPE (if present) & prefix columns\n",
    "# ---------------------------\n",
    "# Drop raw CUSTOMER_TYPE if present (we only want the one-hot columns)\n",
    "if 'CUSTOMER_TYPE' in cust.columns:\n",
    "    cust = cust.drop(columns=['CUSTOMER_TYPE'])\n",
    "\n",
    "# Identify customer feature columns (all except CUSTOMER_ID)\n",
    "cust_feat_cols = [c for c in cust.columns if c != 'CUSTOMER_ID']\n",
    "\n",
    "# Prefix them to avoid collisions after merge\n",
    "cust_prefixed = cust.rename(columns={c: f\"cust_{c}\" for c in cust_feat_cols})\n",
    "# keep the key\n",
    "cust_prefixed = cust_prefixed[['CUSTOMER_ID'] + [f\"cust_{c}\" for c in cust_feat_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3796e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 3) Prepare store frame: prefix store columns (except STORE_NUMBER)\n",
    "# ---------------------------\n",
    "store_feat_cols = [c for c in store.columns if c != 'STORE_NUMBER']\n",
    "store_prefixed = store.rename(columns={c: f\"store_{c}\" for c in store_feat_cols})\n",
    "store_prefixed = store_prefixed[['STORE_NUMBER'] + [f\"store_{c}\" for c in store_feat_cols]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3023e418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders: 1414410 rows; after customer-join: 1414410 rows\n",
      "Orders with NO matching customer record: 0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 4) Left join orders <- customers\n",
    "# ---------------------------\n",
    "merged = orders.merge(cust_prefixed, on='CUSTOMER_ID', how='left', validate='m:1')\n",
    "\n",
    "print(f\"Orders: {n_orders} rows; after customer-join: {len(merged)} rows\")\n",
    "\n",
    "# Count how many orders had no matching customer row (before we fill defaults)\n",
    "cust_missing_count = merged[[f\"cust_{c}\" for c in cust_feat_cols]].isna().all(axis=1).sum()\n",
    "print(f\"Orders with NO matching customer record: {cust_missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae81d64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After store-join: 1414410 rows\n",
      "Orders with NO matching store record: 48223\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 5) Left join (orders+cust) <- stores\n",
    "# ---------------------------\n",
    "merged = merged.merge(store_prefixed, on='STORE_NUMBER', how='left', validate='m:1')\n",
    "print(f\"After store-join: {len(merged)} rows\")\n",
    "\n",
    "# Count how many orders have no matching store info\n",
    "# We'll look for missing STATE in store (store_STATE is expected); otherwise fall back to any store column\n",
    "store_state_col = next((c for c in merged.columns if c.lower().endswith('state') and c.startswith('store_')), None)\n",
    "if store_state_col:\n",
    "    store_missing_count = merged[store_state_col].isna().sum()\n",
    "else:\n",
    "    # fallback — check any store_ column\n",
    "    store_cols = [c for c in merged.columns if c.startswith('store_')]\n",
    "    store_missing_count = merged[store_cols].isna().all(axis=1).sum() if store_cols else 0\n",
    "\n",
    "print(f\"Orders with NO matching store record: {store_missing_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1c7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 6) Fill defaults for customer one-hot columns\n",
    "#    - registered, guest (0/1) -> fill 0 when unknown\n",
    "#    - special_membership -> fill 1 when the original CUSTOMER_TYPE was NaN or customer absent\n",
    "# ---------------------------\n",
    "# Determine cust column names (after prefix)\n",
    "cust_cols_prefixed = [c for c in merged.columns if c.startswith('cust_')]\n",
    "\n",
    "# If the exact names exist (expected from earlier step) use them; otherwise just handle all cust_ columns\n",
    "# Create a boolean mask for rows that have no customer info (all cust_ cols are NA)\n",
    "if cust_cols_prefixed:\n",
    "    missing_cust_mask = merged[cust_cols_prefixed].isna().all(axis=1)\n",
    "    # Fill registered/guest with 0 where missing; fill special with 1 where missing\n",
    "    # If you have specific named columns, handle explicitly:\n",
    "    if 'cust_registered' in merged.columns and 'cust_guest' in merged.columns and 'cust_special_membership' in merged.columns:\n",
    "        merged['cust_registered'] = merged['cust_registered'].fillna(0).astype(int)\n",
    "        merged['cust_guest'] = merged['cust_guest'].fillna(0).astype(int)\n",
    "        # temporarily fill special with 0, then set to 1 where mask==True\n",
    "        merged['cust_special_membership'] = merged['cust_special_membership'].fillna(0).astype(int)\n",
    "        merged.loc[missing_cust_mask, 'cust_special_membership'] = 1\n",
    "    else:\n",
    "        # Generic fallback: fill all cust_ NA -> 0 (safe) and set a synthetic flag if all were NA\n",
    "        merged[cust_cols_prefixed] = merged[cust_cols_prefixed].fillna(0)\n",
    "        # create an indicator\n",
    "        merged['cust_info_missing'] = missing_cust_mask.astype(int)\n",
    "else:\n",
    "    print(\"No customer feature columns found with prefix 'cust_' — skipping cust fill step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe0f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 7) Fill defaults for store columns\n",
    "#    - city dummies -> fill 0\n",
    "#    - store_STATE -> fill 'Unknown'\n",
    "#    - store_city_missing / store_state_missing -> fill 1 where missing store\n",
    "# ---------------------------\n",
    "store_cols_prefixed = [c for c in merged.columns if c.startswith('store_')]\n",
    "\n",
    "# Identify city dummy columns (common prefix used earlier was 'city_' inside store, so now becomes 'store_city_')\n",
    "store_city_cols = [c for c in store_cols_prefixed if c.startswith('store_city_')]\n",
    "\n",
    "# Fill city dummies with 0\n",
    "if store_city_cols:\n",
    "    merged[store_city_cols] = merged[store_city_cols].fillna(0).astype(int)\n",
    "\n",
    "# Fill state\n",
    "if store_state_col:\n",
    "    merged[store_state_col] = merged[store_state_col].fillna('Unknown')\n",
    "else:\n",
    "    # nothing to fill specifically, but ensure other store cols are not NaN\n",
    "    merged[store_cols_prefixed] = merged[store_cols_prefixed].fillna(0)\n",
    "\n",
    "# Fill known store-missing indicator flags if they exist (store_city_missing, store_state_missing)\n",
    "for flag in ['store_city_missing', 'store_state_missing']:\n",
    "    if flag in merged.columns:\n",
    "        # if merge resulted in NA (no store row), mark missing (1)\n",
    "        merged[flag] = merged[flag].fillna(1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "385f87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final master shape: (1414410, 175)\n",
      "Columns sample: ['CUSTOMER_ID', 'STORE_NUMBER', 'ORDER_CREATED_DATE', 'ORDER_ID', 'ORDER_CHANNEL_NAME', 'ORDER_SUBCHANNEL_NAME', 'ORDER_OCCASION_NAME', '$19.99 Crispy Feast', '10 pc Grilled Wings', '10 pc Grilled Wings Combo', '10 pc Mixed Wings', '10 pc Mixed Wings Combo', '10 pc Spicy Wings', '10 pc Spicy Wings Combo', '100 pc Family Grilled Wings', '100 pc Family Mixed Wings', '100 pc Family Spicy Wings', '100 pc Grilled Wings', '100 pc Mixed Wings', '100 pc Spicy Wings', '15 pc Crispy Strips', '15 pc Grilled Wings', '15 pc Grilled Wings Combo', '15 pc Mixed Wings', '15 pc Mixed Wings Combo', '15 pc Spicy Wings', '15 pc Spicy Wings Combo', '2 pc Crispy Strips', '20 Oz Soda', '20 pc Crispy Strips', '20 pc Grilled Wings', '20 pc Mixed Wings', '20 pc Spicy Wings', '20pc Spicy Feast Deal', '24 pc Family Grilled Wings', '24 pc Family Mixed Wings', '24 pc Family Spicy Wings', '25 pc Game Day Pack', '3 Strips Lunch', '3 pc Crispy Strips Combo']\n",
      "Sample counts -> matched_customers (non-null registered flag): 1414410\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 8) Sanity checks\n",
    "# ---------------------------\n",
    "#  - number of rows should equal original orders row count\n",
    "assert len(merged) == n_orders, \"Row count changed — check join keys / duplicates\"\n",
    "\n",
    "print(\"Final master shape:\", merged.shape)\n",
    "print(\"Columns sample:\", merged.columns.tolist()[:40])\n",
    "\n",
    "# Optional: count of distinct customers/stores matched\n",
    "matched_customers = merged['cust_registered'].notna().sum() if 'cust_registered' in merged.columns else None\n",
    "print(\"Sample counts -> matched_customers (non-null registered flag):\", matched_customers)\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05775b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved master dataset to: master_orders_customers_stores.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# 9) Save final master CSV\n",
    "# ---------------------------\n",
    "merged.to_csv(out_fp, index=False)\n",
    "print(\"Saved master dataset to:\", out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9904d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sample = merged.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cbd6d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sample.to_csv(\"final_sample.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
